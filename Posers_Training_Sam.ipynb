{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Posers_Training_Sam.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdFwa1PjcMwO8A5KIv7H4S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"INzcPzhvKpFZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"1be1f45b-9718-40b3-c3df-03caedf3a952","executionInfo":{"status":"ok","timestamp":1588526396756,"user_tz":240,"elapsed":24755,"user":{"displayName":"Quoc Sam Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJn5VNxnpqd3R9fz4euzZ7_1DlICbVqA40Obwkmyc=s64","userId":"15234788601438908122"}}},"source":["from google.colab import drive, files\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wBSG2ym8Lq_O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e7265a8f-55fa-4d55-ecf7-c3f76fab40b0","executionInfo":{"status":"ok","timestamp":1588526397677,"user_tz":240,"elapsed":25660,"user":{"displayName":"Quoc Sam Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJn5VNxnpqd3R9fz4euzZ7_1DlICbVqA40Obwkmyc=s64","userId":"15234788601438908122"}}},"source":["%cd \"/content/drive/My Drive/Colab Notebooks/deep-learning-group\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/deep-learning-group\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pQUwmOd9Ls-m","colab_type":"code","colab":{}},"source":["import autoreload\n","%load_ext autoreload"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1Xtdfw3LueP","colab_type":"code","colab":{}},"source":["%reload_ext autoreload"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLj2FWFWLvtz","colab_type":"code","colab":{}},"source":["import glob\n","import cv2\n","import numpy as np\n","import os\n","\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, AveragePooling2D, Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","import helpers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca1HcJ-0eHkc","colab_type":"code","colab":{}},"source":["DATA_DIR = '/content/drive/My Drive/Colab Notebooks/dataset'\n","\n","batch_size_train = 200\n","val_size_train = 30\n","\n","colorMode = 'rgb'\n","classMode = \"categorical\"\n","imgSize = 64\n","\n","\n","datagen = ImageDataGenerator(rotation_range=20,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1, \n","                             rescale=1./255,\n","                             zoom_range=0.3,\n","                             validation_split=0.2,\n","                             horizontal_flip=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bwtXMhoeOdK3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"2d2329ca-65e0-4a34-8c21-a9c05ba9da52","executionInfo":{"status":"ok","timestamp":1588529747658,"user_tz":240,"elapsed":983,"user":{"displayName":"Quoc Sam Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJn5VNxnpqd3R9fz4euzZ7_1DlICbVqA40Obwkmyc=s64","userId":"15234788601438908122"}}},"source":["train_generator = datagen.flow_from_directory(DATA_DIR,\n","                                            target_size=(imgSize, imgSize),\n","                                            color_mode=colorMode,\n","                                            class_mode=classMode,\n","                                            batch_size=batch_size_train,\n","                                            subset='training')\n","\n","validation_generator = datagen.flow_from_directory(DATA_DIR,\n","                                            target_size=(imgSize, imgSize),\n","                                            color_mode=colorMode,\n","                                            class_mode=classMode,\n","                                            batch_size=batch_size_train,\n","                                            subset='validation')"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Found 1044 images belonging to 17 classes.\n","Found 254 images belonging to 17 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E7fMuxZbgDyy","colab_type":"text"},"source":["**Simple CNN model**"]},{"cell_type":"code","metadata":{"id":"WOiCT-LiOe92","colab_type":"code","colab":{}},"source":["cvsores_1 = []\n","def get_compiled_model_1(optimizer='adam', loss='categorical_crossentropy'):\n","  keras.backend.clear_session()\n","  model = Sequential([\n","                      Conv2D(32, activation='relu', kernel_size=3, input_shape=(imgSize, imgSize, 3)),\n","                      MaxPooling2D(pool_size=(2, 2)),\n","                      # Conv2D(64, activation='relu', kernel_size=3),\n","                      # MaxPooling2D(pool_size=(2, 2)),\n","                      # Conv2D(32, activation='relu', kernel_size=3),\n","                      # MaxPooling2D(pool_size=(2, 2)),\n","                      Conv2D(32, activation='relu', kernel_size=3),\n","                      MaxPooling2D(pool_size=(2, 2)),\n","                      Flatten(),\n","                      Dense(128, activation='relu'),\n","                      Dense(17, activation='softmax')\n","  ])\n","  model.compile(optimizer=optimizer,\n","                loss=loss,\n","                metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zf9WoegwiqFI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"46b270e0-cd41-4a75-a455-8f1e85857a71"},"source":["model_1 = get_compiled_model_1()\n","\n","model_1.fit_generator(train_generator,\n","            steps_per_epoch=100,\n","            epochs=10,\n","            validation_data=validation_generator,\n","            validation_steps=30)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","  2/100 [..............................] - ETA: 1:14 - loss: 3.0122 - accuracy: 0.0656"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["100/100 [==============================] - 135s 1s/step - loss: 2.3253 - accuracy: 0.2834 - val_loss: 1.9137 - val_accuracy: 0.4202\n","Epoch 2/10\n","100/100 [==============================] - 135s 1s/step - loss: 1.5613 - accuracy: 0.5172 - val_loss: 1.6686 - val_accuracy: 0.5036\n","Epoch 3/10\n"," 21/100 [=====>........................] - ETA: 1:40 - loss: 1.3473 - accuracy: 0.5756"],"name":"stdout"}]}]}